# Streamlit Secrets Configuration Example
# Copy this file to secrets.toml (without .example) and configure as needed

# ============================================================
# ONLINE RETRAINING CONFIGURATION
# ============================================================

# ⚠️ STREAMLIT CLOUD INCOMPATIBILITY WARNING ⚠️
# Online retraining causes SEGMENTATION FAULTS on Streamlit Cloud
# PyTorch RL training is incompatible with Streamlit's file watcher
# 
# Options:
#   "false" = STABLE - Data collection only (RECOMMENDED for cloud)
#   "true"  = UNSTABLE - Will crash on Streamlit Cloud (local development only)
#
# Default: false (DISABLED)

ENABLE_RETRAINING = "false"

# ============================================================
# RECOMMENDED SETTINGS
# ============================================================

# For Streamlit Cloud Deployment (REQUIRED):
#   ENABLE_RETRAINING = "false"
#   - ✅ 100% stable, zero crashes
#   - ✅ Data collection enabled
#   - ✅ Download data and retrain offline
#   - ✅ Deploy updated model when ready
#
# For Local Development/Testing Only:
#   ENABLE_RETRAINING = "true"
#   - ⚠️ Test retraining functionality locally
#   - ⚠️ NEVER use on Streamlit Cloud
#   - ⚠️ Will cause segmentation faults in cloud
#   - ✅ Works fine on local machine with 4GB+ RAM

# ============================================================
# ⚠️ DO NOT ENABLE RETRAINING ON STREAMLIT CLOUD ⚠️
# ============================================================

# DOCUMENTED ISSUE: PyTorch RL training is incompatible with Streamlit Cloud
#
# Error: RuntimeError: Tried to instantiate class '__path__._path'
# Result: Segmentation fault after model.learn() is called
#
# This is a KNOWN LIMITATION of Streamlit Cloud, not a bug in this code.
#
# ❌ DO NOT TRY TO ENABLE - It will crash your app
# ✅ USE OFFLINE RETRAINING - See RETRAINING_GUIDE.md
#
# If you attempt to enable with ENABLE_RETRAINING = "true", the app will:
# 1. Display a red warning banner
# 2. Crash with segmentation fault after 5 patient entries
# 3. Become unstable and unusable

# ============================================================
# MEMORY OPTIMIZATIONS APPLIED
# ============================================================

# The app includes these optimizations (for local development):
# - Reduced timesteps: 200 (instead of 1000)
# - Aggressive garbage collection
# - PyTorch cache clearing
# - Environment cleanup after each training
# - Error recovery with memory cleanup
# - Lazy torch import to reduce file watcher conflicts
#
# However, these optimizations CANNOT prevent the fundamental
# incompatibility between PyTorch RL and Streamlit Cloud.
#
# CONCLUSION: Online retraining is NOT POSSIBLE on Streamlit Cloud.
# Use the stable offline retraining workflow documented in RETRAINING_GUIDE.md
